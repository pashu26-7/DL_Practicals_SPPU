{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EgBKAWni6t99"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "from keras.applications import VGG16\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "aSmqaVzD6u-H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: Extract dataset locally ===\n",
    "zip_path = r\"C:\\Users\\Parth\\Documents\\Jupyter\\DataSet_Practical6.zip\"\n",
    "extract_path = r\"C:\\Users\\Parth\\Documents\\Jupyter\\Datasets\"\n",
    "# Extract ZIP to a local folder\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"✅ Extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pDPtikfZ6xRQ"
   },
   "outputs": [],
   "source": [
    "# === STEP 2: Set correct dataset directories (Jupyter paths, not /content/) ===\n",
    "train_dir = os.path.join(extract_path, \"trainingSet\")\n",
    "test_dir = os.path.join(extract_path, \"testSet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "trHAXFc-62mv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42000 images belonging to 1 classes.\n",
      "Found 28000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# === STEP 3: Create ImageDataGenerators ===\n",
    "img_gen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = img_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=5000,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_gen = img_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=5000,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xARprwn265OH",
    "outputId": "a600112d-e032-4ab2-a674-040b0e884c78"
   },
   "outputs": [],
   "source": [
    "# === STEP 4: Load images and labels ===\n",
    "x_train, y_train = train_gen[0]\n",
    "x_test, y_test = test_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldo3QYgH673-",
    "outputId": "b5e25e74-f69b-458d-9dd8-2eef96fe2e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = img_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32,32),\n",
    "    batch_size=5000,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "5tMuBpj869Ln"
   },
   "outputs": [],
   "source": [
    "# === STEP 5: Build VGG16 + Custom Classifier ===\n",
    "vgg_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hhdd0a46_sM",
    "outputId": "6f77be41-872b-40b8-e712-dedfcef89cac"
   },
   "outputs": [],
   "source": [
    "# Freeze pretrained layers initially\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "custom_classifier = keras.Sequential([\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(train_gen.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    vgg_model,\n",
    "    custom_classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LJ2yRzuW7B8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data shapes:\n",
      "x_train: (5000, 32, 32, 3) y_train: (5000, 1)\n",
      "x_test: (5000, 32, 32, 3) y_test: (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# === STEP 6: Compile model ===\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"✅ Data shapes:\")\n",
    "print(\"x_train:\", x_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"x_test:\", x_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "xE3qizov7Gt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PARTH\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:946: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\PARTH\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x219a4144590>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === STEP 7: Initial training ===\n",
    "model.fit(\n",
    "    x_train[:1000], y_train[:1000],\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test[:500], y_test[:500])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CYeknWf97LDU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/2\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x219a40bf350>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === STEP 8: Fine-tune last few VGG16 layers ===\n",
    "for layer in vgg_model.layers[:-4]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDiMrPDM7MSp",
    "outputId": "1b8e0d19-77b1-4270-9fdf-7b0c0ccbece9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "✅ Test Loss: 0.0000, Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# === STEP 9: Evaluate model ===\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"✅ Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXexjTHl7QeC",
    "outputId": "12f4bdfd-60a9-4524-948d-d145eada564c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PARTH\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:946: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 255ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === STEP 10: Predict and visualize ===\n",
    "pred = model.predict(x_test)\n",
    "labels = list(train_gen.class_indices.keys())\n",
    "\n",
    "plt.imshow(x_test[10])\n",
    "plt.title(f\"Predicted: {labels[np.argmax(pred[10])]} | True: {labels[np.argmax(y_test[10])]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
